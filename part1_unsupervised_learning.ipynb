{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c51f80b694da894627ba37be28c86055",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "- TAs: Tong Zeng <tozeng@syr.edu>, Priya Matnani <psmatnan@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these packages\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import clustering\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Unsupervised learning\n",
    "\n",
    "I would recommend to follow the notebook `unsupervised_learning.ipynb` first, shared through the IST 718 repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataset contains information about dozens of \"data science\" programs across the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "217136238553b4e5dc984196253f311e",
     "grade": false,
     "grade_id": "cell-8898c04579b9221e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ds_programs_df = spark.read.csv('/datasets/colleges_data_science_programs.csv',\n",
    "                               inferSchema=True, header=True).\\\n",
    "                 fillna('').orderBy('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: (10 pts)\n",
    "\n",
    "This dataset contains many columns that we can use to understand how these data science programs differ from one another. In this question, you will create a dataframe `ds_programs_text_df` which simply adds a column `text` to the dataframe `ds_programs_df`. This column will have the concatenation of the following columns separated by a space: `program`, `degree` and `department` (find the appropriate function in the `fn` package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cb982914cbab5d8d552cafcab8a6f41b",
     "grade": false,
     "grade_id": "cell-18ebd4f77c37a8e3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# (10 pts) Create ds_programs_text_df here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the `ds_programs_text_df` should give you:\n",
    "\n",
    "```python\n",
    "ds_programs_text_df.orderBy('id').first().text\n",
    "```\n",
    "\n",
    "```console\n",
    "'Data Science Masters Mathematics and Statistics'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed593a17eab4017a9129cd4ad457fc98",
     "grade": true,
     "grade_id": "cell-20fb7c865c3ddf0e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (10 pts)\n",
    "np.testing.assert_equal(ds_programs_text_df.count(), 222)\n",
    "np.testing.assert_equal(set(ds_programs_text_df.columns), {'admit_reqs',\n",
    " 'business',\n",
    " 'capstone',\n",
    " 'cost',\n",
    " 'country',\n",
    " 'courses',\n",
    " 'created_at',\n",
    " 'databases',\n",
    " 'degree',\n",
    " 'department',\n",
    " 'ethics',\n",
    " 'id',\n",
    " 'machine learning',\n",
    " 'mapreduce',\n",
    " 'name',\n",
    " 'notes',\n",
    " 'oncampus',\n",
    " 'online',\n",
    " 'part-time',\n",
    " 'program',\n",
    " 'program_size',\n",
    " 'programminglanguages',\n",
    " 'state',\n",
    " 'text',\n",
    " 'university_count',\n",
    " 'updated_at',\n",
    " 'url',\n",
    " 'visualization', \n",
    " 'year_founded'})\n",
    "np.testing.assert_array_equal(ds_programs_text_df.orderBy('id').rdd.map(lambda x: x.text).take(5),\n",
    "                              ['Data Science Masters Mathematics and Statistics',\n",
    " 'Analytics Masters Business and Information Systems',\n",
    " 'Data Science Masters Computer Science',\n",
    " 'Business Intelligence & Analytics Masters Business',\n",
    " 'Advanced Computer Science(Data Analytics) Masters Computer Science'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: (10 pts) \n",
    "\n",
    "The following code creates a dataframe `ds_features_df` which adds a column `features` to `ds_programs_text_df` that contains the `tfidf` of the column `text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2cb3933b05c489ba7cadcdc1a3abc02d",
     "grade": false,
     "grade_id": "cell-8d401e50a125c6f3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# read-only\n",
    "pipe_features = \\\n",
    "    Pipeline(stages=[\n",
    "        feature.Tokenizer(inputCol='text', outputCol='words'),\n",
    "        feature.CountVectorizer(inputCol='words', outputCol='tf'),\n",
    "        feature.IDF(inputCol='tf', outputCol='tfidf'),\n",
    "        feature.StandardScaler(withStd=False, withMean=True, inputCol='tfidf', outputCol='features')]).\\\n",
    "    fit(ds_programs_text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline model `pipe_pca` that computes the two first principal components of `features` as computed by `pipe_features` and outputs a column `pc`. Use that pipeline to create a dataframe `ds_features_df` with the columns `id`, `name`, `url`, and `pc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fe5246f975004002ec6318349b882137",
     "grade": false,
     "grade_id": "cell-cab09e882ef8f6d1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the pipe_pca PipelineModel below (10 pts)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd76439d72e701ddd0a2bf23df5affc1",
     "grade": true,
     "grade_id": "cell-b31329e505038ee3",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for (10 pts)\n",
    "np.testing.assert_equal(pipe_pca.stages[0],  pipe_features)\n",
    "np.testing.assert_equal(type(pipe_pca.stages[1]),  feature.PCAModel)\n",
    "np.testing.assert_equal(set(ds_features_df.columns), {'id', 'name', 'pc', 'url'})\n",
    "np.testing.assert_equal(ds_features_df.first().pc.shape, (2, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: (10 pts)\n",
    "\n",
    "Create a scatter plot with the x axis containing the first principal component and the y axis containing the second principal component of `ds_features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "25f8bfc0359ff722d557a39233e1bfe2",
     "grade": true,
     "grade_id": "cell-cfe761874325794d",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# below perform the appropriate \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 (10 pts)\n",
    "\n",
    "Create two Pandas dataframes `pc1_pd` and `pc2_pd` with the columns `word` and `abs_loading` that contain the top 5 words in absolute loading for the principal components 1 and 2, respetively. You can extract the vocabulary from the stage that contains the count vectorizer in `pipe_features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "21ba70a5a4393b6c5f5d5ce14bca6f26",
     "grade": false,
     "grade_id": "cell-f9d1641edcc927e5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8938af66299fabeeec8ed71ca0955592",
     "grade": true,
     "grade_id": "cell-6d6497bbef7511c8",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (10 pts)\n",
    "assert type(pc1_pd) == pd.core.frame.DataFrame\n",
    "assert type(pc2_pd) == pd.core.frame.DataFrame\n",
    "np.testing.assert_array_equal(pc1_pd.shape, (5, 2))\n",
    "np.testing.assert_array_equal(pc2_pd.shape, (5, 2))\n",
    "np.testing.assert_equal(set(pc1_pd.columns), {'abs_loading', 'word'})\n",
    "np.testing.assert_equal(set(pc2_pd.columns), {'abs_loading', 'word'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: (10 pts)\n",
    "\n",
    "Create a new pipeline for PCA called `pipe_pca2` where you fit 50 principal components. Extract the the `PCAModel` from the stages of this pipeline, and assign to a variable `explainedVariance` the variance explained by components of such model. Finally, assign to a variable `best_k` the value $k$ such that ($k+1$)-th component is not able to explain more than 0.01 variance. You can use a for-loop to find such best k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8f1eb781acb7a61a4176067666602247",
     "grade": false,
     "grade_id": "cell-3c9669871f98d13c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3dbe273df3603e6abf6b49f60bac91e7",
     "grade": true,
     "grade_id": "cell-ccc5cf39716a4854",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for (10 pts)\n",
    "np.testing.assert_equal(pipe_pca2.stages[0],  pipe_features)\n",
    "np.testing.assert_equal(type(pipe_pca2.stages[1]),  feature.PCAModel)\n",
    "np.testing.assert_equal(len(explainedVariance), 50)\n",
    "np.testing.assert_array_less(5, best_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
