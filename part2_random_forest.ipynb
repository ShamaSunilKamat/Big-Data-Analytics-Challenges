{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c51f80b694da894627ba37be28c86055",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "- TAs: Tong Zeng <tozeng@syr.edu>, Priya Matnani <psmatnan@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these packages\n",
    "import pyspark\n",
    "from pyspark.ml import feature, classification\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these questions, we will examine the famous Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f0c5e45b6f138ba0d550dff214ce7ee7",
     "grade": false,
     "grade_id": "cell-219523fd6f45f014",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- is_male: float (nullable = false)\n",
      " |-- pclass: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read-only\n",
    "drop_cols = ['boat', 'body']\n",
    "titanic_df = spark.read.csv('/datasets/titanic_original.csv', header=True, inferSchema=True).\\\n",
    "    drop(*drop_cols).\\\n",
    "    fillna('O').\\\n",
    "    dropna(subset=['pclass', 'age', 'sibsp', 'parch', 'fare', 'survived']).\\\n",
    "    select((fn.col('sex') == 'male').alias('is_male').cast('float'),           \n",
    "           'pclass',\n",
    "           'age',\n",
    "           'sibsp',\n",
    "           'parch',\n",
    "           'fare',\n",
    "           'survived')\n",
    "training_df, validation_df, testing_df = titanic_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: (10 pts)\n",
    "\n",
    "Create three pipelines that contain three different random forest classifiers that take in all features from the `titanic_df` (`is_male`, `pclass`, `age`, `sibsp`, `parch`, and `fare`) to predict whether someone survived (`survived`). Fit these pipelines to the training data\n",
    "\n",
    "- `pipe_rf1`: Random forest with `maxDepth=1` and `numTrees=60`\n",
    "- `pipe_rf2`: Random forest with `maxDepth=3` and `numTrees=40`\n",
    "- `pipe_rf3`: Random forest with `maxDepth=6`, `numTrees=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2912f0aa0562283b8c2b9b8d330a9e8c",
     "grade": false,
     "grade_id": "cell-5d34f31b40350198",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipelines `pipe_rf1`, `pipe_rf2`, and `pipe_rf3` here\n",
    "# YOUR CODE HERE\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "va = VectorAssembler().setInputCols(training_df.columns[0:6]).setOutputCol('features')\n",
    "rf1 = RandomForestClassifier(labelCol=\"survived\", featuresCol=\"features\", maxDepth=1,numTrees=60)\n",
    "rf2 = RandomForestClassifier(labelCol=\"survived\", featuresCol=\"features\", maxDepth=3,numTrees=40)\n",
    "rf3 = RandomForestClassifier(labelCol=\"survived\", featuresCol=\"features\", maxDepth=6,numTrees=20)\n",
    "pipe_rf1=Pipeline(stages=[va, rf1]).fit(training_df)\n",
    "pipe_rf2=Pipeline(stages=[va, rf2]).fit(training_df)\n",
    "pipe_rf3=Pipeline(stages=[va, rf3]).fit(training_df)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e2a89f91478bdb2730403466238e2afb",
     "grade": true,
     "grade_id": "cell-896bdef9bf893231",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[1]), classification.RandomForestClassificationModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[1]), classification.RandomForestClassificationModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[1]), classification.RandomForestClassificationModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf2.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf3.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (10 pts)\n",
    "\n",
    "Use the following evaluator to compute the area under the curve of the models on validation data. Print the AUC of the three models and assign the best one (i.e., the best pipeline) to a variable `best_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluation.BinaryClassificationEvaluator(labelCol='survived')\n",
    "# use it as follows:\n",
    "# evaluator.evaluate(fitted_pipeline.transform(df)) -> AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "05aa55bb93c8241e41bb5608503701cc",
     "grade": false,
     "grade_id": "cell-91cd57be67b86f2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "AUC1=evaluator.evaluate(pipe_rf1.transform(validation_df))\n",
    "AUC2=evaluator.evaluate(pipe_rf2.transform(validation_df))\n",
    "AUC3=evaluator.evaluate(pipe_rf3.transform(validation_df))\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8182622582872928"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC1\n",
    "#0.8182622582872928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348584254143648"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC2\n",
    "#0.8348584254143648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445916781767949"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC3\n",
    "#0.8445916781767949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=pipe_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fcc6929a6980dc7344129a20ed357368",
     "grade": true,
     "grade_id": "cell-5399ae6afb414351",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "np.testing.assert_equal(type(best_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(best_model.stages[1]), classification.RandomForestClassificationModel)\n",
    "np.testing.assert_equal(type(best_model.transform(validation_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: 5 pts\n",
    "\n",
    "Compute the AUC of the model on testing data, print it, and assign it to variable `AUC_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d024cc767cf9091d250f11c6c26fc729",
     "grade": false,
     "grade_id": "cell-86f5f0eaa917209f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create AUC_best below\n",
    "# YOUR CODE HERE\n",
    "AUC_best=evaluator.evaluate(pipe_rf3.transform(testing_df))\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4022447619c7d4c0bba88e0737cf38c4",
     "grade": true,
     "grade_id": "cell-bd2f7d28b44ac691",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_array_less(AUC_best, 1.)\n",
    "np.testing.assert_array_less(0.5, AUC_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104813315339629"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_best\n",
    "#0.9104813315339629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: 5 pts\n",
    "\n",
    "Using the parameters of the best model, create a new pipeline called `final_model` and fit it to the entire data (`titanic_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f1e9753be63f387d37db812d4102e26c",
     "grade": false,
     "grade_id": "cell-2574a5ca8f12ce94",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipeline `final_model` here\n",
    "# YOUR CODE HERE\n",
    "final_model= Pipeline(stages=[va, rf3]).fit(titanic_df)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a017f4a6fc945d5450684c54f9632960",
     "grade": true,
     "grade_id": "cell-bcce92747a0d2ba5",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_equal(type(final_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(final_model.stages[1]), classification.RandomForestClassificationModel)\n",
    "np.testing.assert_equal(type(final_model.transform(titanic_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: 10 + 5 pts\n",
    "\n",
    "Create a pandas dataframe `feature_importance` with the columns `feature` and `importance` which contains the names of the features (`is_male`, `pclass`, etc.) and their feature importance as determined by the random forest of the final model. Sort the dataframe by `importance` in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "89dc0c52dff983147af006f48049dd3e",
     "grade": false,
     "grade_id": "cell-5b666b921af5a375",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create feature_importance below\n",
    "# YOUR CODE HERE\n",
    "rf_model = final_model.stages[-1]\n",
    "feature_importance= pd.DataFrame(list(zip(titanic_df.columns[0:6], rf_model.featureImportances.toArray())),\n",
    "            columns = ['feature', 'importance']).sort_values('importance', ascending= False)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_male</td>\n",
       "      <td>0.465462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fare</td>\n",
       "      <td>0.168049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pclass</td>\n",
       "      <td>0.148183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.143203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>0.039139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parch</td>\n",
       "      <td>0.035964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  importance\n",
       "0  is_male    0.465462\n",
       "5     fare    0.168049\n",
       "1   pclass    0.148183\n",
       "2      age    0.143203\n",
       "3    sibsp    0.039139\n",
       "4    parch    0.035964"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display it here\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a174ad97cc20a8fe9385ded1a56597f7",
     "grade": true,
     "grade_id": "cell-de7873ad0b54f277",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "assert type(feature_importance) == pd.core.frame.DataFrame\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-----+-----+--------+--------+\n",
      "|is_male|pclass|   age|sibsp|parch|    fare|survived|\n",
      "+-------+------+------+-----+-----+--------+--------+\n",
      "|    0.0|     1|  29.0|    0|    0|211.3375|       1|\n",
      "|    1.0|     1|0.9167|    1|    2|  151.55|       1|\n",
      "|    0.0|     1|   2.0|    1|    2|  151.55|       0|\n",
      "|    1.0|     1|  30.0|    1|    2|  151.55|       0|\n",
      "|    0.0|     1|  25.0|    1|    2|  151.55|       0|\n",
      "|    1.0|     1|  48.0|    0|    0|   26.55|       1|\n",
      "|    0.0|     1|  63.0|    1|    0| 77.9583|       1|\n",
      "|    1.0|     1|  39.0|    0|    0|     0.0|       0|\n",
      "|    0.0|     1|  53.0|    2|    0| 51.4792|       1|\n",
      "|    1.0|     1|  71.0|    0|    0| 49.5042|       0|\n",
      "|    1.0|     1|  47.0|    1|    0| 227.525|       0|\n",
      "|    0.0|     1|  18.0|    1|    0| 227.525|       1|\n",
      "|    0.0|     1|  24.0|    0|    0|    69.3|       1|\n",
      "|    0.0|     1|  26.0|    0|    0|   78.85|       1|\n",
      "|    1.0|     1|  80.0|    0|    0|    30.0|       1|\n",
      "|    1.0|     1|  24.0|    0|    1|247.5208|       0|\n",
      "|    0.0|     1|  50.0|    0|    1|247.5208|       1|\n",
      "|    0.0|     1|  32.0|    0|    0| 76.2917|       1|\n",
      "|    1.0|     1|  36.0|    0|    0| 75.2417|       0|\n",
      "|    1.0|     1|  37.0|    1|    1| 52.5542|       1|\n",
      "|    0.0|     1|  47.0|    1|    1| 52.5542|       1|\n",
      "|    1.0|     1|  26.0|    0|    0|    30.0|       1|\n",
      "|    0.0|     1|  42.0|    0|    0| 227.525|       1|\n",
      "|    0.0|     1|  29.0|    0|    0|221.7792|       1|\n",
      "|    1.0|     1|  25.0|    0|    0|    26.0|       0|\n",
      "|    1.0|     1|  25.0|    1|    0| 91.0792|       1|\n",
      "|    0.0|     1|  19.0|    1|    0| 91.0792|       1|\n",
      "|    0.0|     1|  35.0|    0|    0|135.6333|       1|\n",
      "|    1.0|     1|  28.0|    0|    0|   26.55|       1|\n",
      "|    1.0|     1|  45.0|    0|    0|    35.5|       0|\n",
      "|    1.0|     1|  40.0|    0|    0|    31.0|       1|\n",
      "|    0.0|     1|  30.0|    0|    0|164.8667|       1|\n",
      "|    0.0|     1|  58.0|    0|    0|   26.55|       1|\n",
      "|    1.0|     1|  42.0|    0|    0|   26.55|       0|\n",
      "|    0.0|     1|  45.0|    0|    0| 262.375|       1|\n",
      "|    0.0|     1|  22.0|    0|    1|    55.0|       1|\n",
      "|    1.0|     1|  41.0|    0|    0|    30.5|       0|\n",
      "|    1.0|     1|  48.0|    0|    0| 50.4958|       0|\n",
      "|    0.0|     1|  44.0|    0|    0| 27.7208|       1|\n",
      "|    0.0|     1|  59.0|    2|    0| 51.4792|       1|\n",
      "|    0.0|     1|  60.0|    0|    0| 76.2917|       1|\n",
      "|    0.0|     1|  41.0|    0|    0|   134.5|       1|\n",
      "|    1.0|     1|  45.0|    0|    0|   26.55|       0|\n",
      "|    1.0|     1|  42.0|    0|    0| 26.2875|       1|\n",
      "|    0.0|     1|  53.0|    0|    0| 27.4458|       1|\n",
      "|    1.0|     1|  36.0|    0|    1|512.3292|       1|\n",
      "|    0.0|     1|  58.0|    0|    1|512.3292|       1|\n",
      "|    1.0|     1|  33.0|    0|    0|     5.0|       0|\n",
      "|    1.0|     1|  28.0|    0|    0|    47.1|       0|\n",
      "|    1.0|     1|  17.0|    0|    0|    47.1|       0|\n",
      "+-------+------+------+-----+-----+--------+--------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts)** Comment below on the importance that random forest has given to each feature. Are they reasonable? Do they tell you anything valuable about the titanic dataset? Answer in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b2c41f651112504fa5bc52db64459564",
     "grade": true,
     "grade_id": "cell-cd1eb09a9ba5aaa9",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Random forest has given most importance to the gender (is_male) feature followed by fare, pclass, age, sibsp and parch respectively. The information gained by random forest is the maximum from is_male. Yes, they are reasonable because females and children are those who are saved first and then the men if possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6:  5 pts.\n",
    "\n",
    "Pick any of the trees from the final model and assign its `toDebugString` property to a variable `example_tree`. Print this variable and add comments to the cell describing how you think this particular tree is fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b212587e3d2f28ad35f04e2a6149e762",
     "grade": false,
     "grade_id": "cell-7476baa7ceb72c05",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=dtc_c550ad529565) of depth 6 with 97 nodes\n",
      "  If (feature 5 <= 15.8)\n",
      "   If (feature 0 <= 0.5)\n",
      "    If (feature 2 <= 23.25)\n",
      "     If (feature 5 <= 8.658349999999999)\n",
      "      If (feature 2 <= 19.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 2 > 19.5)\n",
      "       If (feature 2 <= 20.75)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 20.75)\n",
      "        Predict: 1.0\n",
      "     Else (feature 5 > 8.658349999999999)\n",
      "      If (feature 3 <= 1.5)\n",
      "       If (feature 3 <= 0.5)\n",
      "        Predict: 1.0\n",
      "       Else (feature 3 > 0.5)\n",
      "        Predict: 0.0\n",
      "      Else (feature 3 > 1.5)\n",
      "       Predict: 0.0\n",
      "    Else (feature 2 > 23.25)\n",
      "     If (feature 1 <= 2.5)\n",
      "      If (feature 3 <= 0.5)\n",
      "       If (feature 2 <= 50.5)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 50.5)\n",
      "        Predict: 0.0\n",
      "      Else (feature 3 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 1 > 2.5)\n",
      "      If (feature 4 <= 0.5)\n",
      "       If (feature 2 <= 30.75)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 30.75)\n",
      "        Predict: 1.0\n",
      "      Else (feature 4 > 0.5)\n",
      "       If (feature 2 <= 27.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 27.5)\n",
      "        Predict: 0.0\n",
      "   Else (feature 0 > 0.5)\n",
      "    If (feature 2 <= 7.5)\n",
      "     If (feature 1 <= 2.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 1 > 2.5)\n",
      "      If (feature 3 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 3 > 0.5)\n",
      "       If (feature 2 <= 2.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 2.5)\n",
      "        Predict: 1.0\n",
      "    Else (feature 2 > 7.5)\n",
      "     If (feature 5 <= 7.7625)\n",
      "      If (feature 1 <= 1.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 1.5)\n",
      "       If (feature 5 <= 7.7375)\n",
      "        Predict: 0.0\n",
      "       Else (feature 5 > 7.7375)\n",
      "        Predict: 0.0\n",
      "     Else (feature 5 > 7.7625)\n",
      "      If (feature 2 <= 21.5)\n",
      "       If (feature 2 <= 19.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 19.5)\n",
      "        Predict: 0.0\n",
      "      Else (feature 2 > 21.5)\n",
      "       If (feature 3 <= 0.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 3 > 0.5)\n",
      "        Predict: 0.0\n",
      "  Else (feature 5 > 15.8)\n",
      "   If (feature 0 <= 0.5)\n",
      "    If (feature 1 <= 2.5)\n",
      "     If (feature 5 <= 26.125)\n",
      "      If (feature 3 <= 0.5)\n",
      "       If (feature 2 <= 22.25)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 22.25)\n",
      "        Predict: 1.0\n",
      "      Else (feature 3 > 0.5)\n",
      "       If (feature 5 <= 21.0375)\n",
      "        Predict: 0.0\n",
      "       Else (feature 5 > 21.0375)\n",
      "        Predict: 1.0\n",
      "     Else (feature 5 > 26.125)\n",
      "      If (feature 5 <= 36.125)\n",
      "       If (feature 5 <= 31.1375)\n",
      "        Predict: 1.0\n",
      "       Else (feature 5 > 31.1375)\n",
      "        Predict: 1.0\n",
      "      Else (feature 5 > 36.125)\n",
      "       If (feature 4 <= 1.5)\n",
      "        Predict: 1.0\n",
      "       Else (feature 4 > 1.5)\n",
      "        Predict: 1.0\n",
      "    Else (feature 1 > 2.5)\n",
      "     If (feature 5 <= 25.9646)\n",
      "      If (feature 2 <= 32.25)\n",
      "       If (feature 2 <= 27.5)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 27.5)\n",
      "        Predict: 0.0\n",
      "      Else (feature 2 > 32.25)\n",
      "       Predict: 1.0\n",
      "     Else (feature 5 > 25.9646)\n",
      "      If (feature 3 <= 1.5)\n",
      "       If (feature 2 <= 38.75)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 38.75)\n",
      "        Predict: 0.0\n",
      "      Else (feature 3 > 1.5)\n",
      "       Predict: 0.0\n",
      "   Else (feature 0 > 0.5)\n",
      "    If (feature 3 <= 1.5)\n",
      "     If (feature 2 <= 13.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 2 > 13.5)\n",
      "      If (feature 2 <= 27.5)\n",
      "       If (feature 2 <= 25.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 25.5)\n",
      "        Predict: 1.0\n",
      "      Else (feature 2 > 27.5)\n",
      "       If (feature 5 <= 26.125)\n",
      "        Predict: 0.0\n",
      "       Else (feature 5 > 26.125)\n",
      "        Predict: 0.0\n",
      "    Else (feature 3 > 1.5)\n",
      "     If (feature 5 <= 25.9646)\n",
      "      If (feature 2 <= 24.25)\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 > 24.25)\n",
      "       If (feature 4 <= 0.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 4 > 0.5)\n",
      "        Predict: 1.0\n",
      "     Else (feature 5 > 25.9646)\n",
      "      If (feature 2 <= 2.5)\n",
      "       If (feature 3 <= 2.5)\n",
      "        Predict: 1.0\n",
      "       Else (feature 3 > 2.5)\n",
      "        Predict: 0.0\n",
      "      Else (feature 2 > 2.5)\n",
      "       Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a variable example_tree with the toDebugString property of a tree from final_model.\n",
    "# print this string and comment in this same cell about the branches that this tree fit\n",
    "# YOUR CODE HERE\n",
    "len(rf_model.trees)\n",
    "example_tree=rf_model.trees[9].toDebugString\n",
    "print(example_tree)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first split is using fare feature and the next split is the gender. These two features have maximum importance as shown above. This justifies why this tree is fitting the data well. It is not overfitting as it is not using is_male as the first split and fare as the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5d8be0a7e3fedc16108ebbb9503a2a7",
     "grade": true,
     "grade_id": "cell-80c89e10a60f6ce2",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 points\n",
    "assert type(example_tree) == str\n",
    "assert 'DecisionTreeClassificationModel' in example_tree\n",
    "assert 'feature 0' in example_tree\n",
    "assert 'If' in example_tree\n",
    "assert 'Else' in example_tree\n",
    "assert 'Predict' in example_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
